#!/usr/bin/env python3

import numpy as np
from collections import Counter
from scipy import interpolate


def create_new_tics(tics, rate, mintic='', maxtic='',option='preserve'):
    """
    This function creates new tics in an attempt to account for missing data using the following settings:

     "gap_fill": enforces a "best fit" by stepping through the acquisition tic times and ensuring that the next sample
    is at least within 1.5x the sampling period.  If it's more than this, it inserts a new sample tic time.
    This works particularly well when samples are skipped in integer values.  If fractional samples are skipped, this
    can become less ideal. This method ensures that the ACTUAL acquired times are used, and the sampling rate is AS CLOSE as possible
     to ideal, however there still may be small variations.  (much less than without this function though).  This will
     probably result in fewer interpolation errors in the future.  This also works well for signal dropout, where data
     is missing for large chunks of time.

    "uniform": this enforces "uniform" sampling.  Starting from the first tic time, it simply creates an array of tics
    till the last tic time.

    "min_error": This enforces uniform sampling, but it starts at an offset which is calculated by minimizing the total
    error between the uniform tic time array and the actual tic time array

    "upsample": This creates a tic timeseries at the highest possible sampling frequency (1 tic).  Then missing values
    are interpolated.  This creates a potentially large array, and there will be many values that need to be interpolated
    depending on the original sampling rate, however the original sample points will be preserved, and can be extracted
    later if desired.  Alternatively, THIS array can be resampled manually at a later time.

    "none": leaves things as they are

    Technically "uniform" and "min_error" have the strictest adherence to a uniform sampling rate and BIDS compliance.

    :param tics: the tic times of the acquisions
    :param rate: the sampling rate (in number of tics per sample)
    :param mintic: you can specify a minimum tic if you wish to expand/contract the time series
    :param maxtic: you can specify a maximum tic if you wish to expand/contract the time series
    :return:
    """

    if mintic:
        min_tic = mintic
    else:
        min_tic = min(tics)

    if maxtic:
        max_tic = maxtic
    else:
        max_tic = max(tics)


    if option == 'gap_fill':

        custom_tics = []

        for it in range(len(tics)-1):

            t1 = tics[it]
            t2 = tics[it+1]
            current_tic = t1

            dt = t2 - t1
            if dt >= rate*1.5:
                custom_tics.append(current_tic)
                while dt >= rate*1.5:
                    current_tic += rate
                    custom_tics.append(current_tic)
                    t1 = current_tic
                    dt = t2 - t1

            else:
                custom_tics.append(current_tic)

        custom_tics.append(t2)

    elif option == 'upsample':
        custom_tics = np.arange(min_tic, max_tic+1, 1)

    elif option == 'uniform':
        custom_tics = np.arange(min_tic, max_tic+rate-1,rate)

    elif option == 'min_error':
        # This option doesn't seem to work

        er=[]
        for i in range(rate*9):
            mnt = min(tics)
            mxt = max(tics)
            temp_tic = np.arange(mnt + i,mxt + rate - 1,rate)
            er.append(np.sum(np.abs(tics[rate*10:rate*1000] - temp_tic[rate*10:rate*1000])))
        i = np.argmin(er)
        print(er)
        custom_tics = np.arange(min_tic+i, max_tic+rate-1,rate)

    elif option =='none':
        custom_tics = tics

    else:
        print('unrecognized option {} in create_new_tics'.format(option))

    return np.array(custom_tics)


def interp_vals(old_tics, old_vals, new_tics, fill='linear'):
    """
    To be used with "create_new_tics".  This function fills in any missing values present in the "new_tics" array
    generated by the create_new_tics function, or otherwise.  Users can specify filling strategy:

    ‘linear’, ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’,
    ‘previous’, ‘next’, where ‘zero’, ‘slinear’, ‘quadratic’ and ‘cubic’ refer to a spline interpolation of zeroth,
    first, second or third order; ‘previous’ and ‘next’ simply return the previous or next value of the point

    This can also be a numerical value, where that value will be filled in to any of the missing locations.  'nan' is
    also allowed, where 'nan's will be put wherever data is missing.

    :param old_tics: The original tics of the sampled data
    :param old_vals: The original values of the sampled data
    :param new_tics: The new tics at the desired times
    :param fill: the fill strategy (an interpolation method or a fill value)
    :return: returns the new array with the values filled appropriately.
    """
    if fill =='nan' or isinstance(fill,int) or isinstance(fill,float):
        new_vals = np.empty(len(new_tics))
        if fill == 'nan':
            print('filling with nans')
            new_vals[:] = np.nan
        else:
            new_vals[:] = fill

        ot = 0
        for it,nt in enumerate(new_tics):

            if ot >= len(old_tics):
                break

            if nt == old_tics[ot]:
                new_vals[it] = old_vals[ot]
                ot+=1
    else:
        f = interpolate.interp1d(old_tics, old_vals, kind=fill,
                                 fill_value=(old_vals[0], old_vals[-1]), bounds_error=False)
        new_vals = f(new_tics)

    return new_vals


def log2dict(physio_log):

    """
    This function takes a standard physio log file as output by CMRR-MB (https://github.com/CMRR-C2P/MB/)
    and converts them to machine-friendly python dictionaries
    :param physio_log: the .log file produced by the CMRR-MB script
    :return: the dictionary is returned
    """

    # physio_log = self.logfile
    # physio_log = '/Users/davidparker/Documents/Flywheel/SSE/MyWork/Gears/BIDs_Physio/extract-cmrr-physio/output/func-bold_task-lokicat_run-01_RESP.log'

    physio_dict = {}
    header = []

    # Set the log file to reference for later
    physio_dict['log_file'] = physio_log
    physio_dict['bids_file'] = ''

    # context.log.debug('loading file')
    f = open(physio_log, 'r')
    # context.log.debug('going through lines')
    for line in f.readlines():

        # Remove trailing endline
        line = line.strip('\n')

        # If there's an equals sign, we're still in the header, and we need to store this value
        if line.find('=') > -1:

            # Create a key, value pair by splitting the line by the equals sign
            pair = line.split('=')

            # store the key and value in the dict (everything as strings for now)
            # After stripping whitespace of course
            physio_dict[pair[0].strip()] = pair[1].strip()

        # Otherwise If it's an empty line, skip it
        elif line == '':
            continue

        # Otherwise, if we remove the spaces and underscores and it's alpha, then it's headers and we need it
        elif line.replace(' ', '').replace('_', '').isalpha():
            header = line.split()
            for h in header:
                physio_dict[h] = []

        # if the first values is numeric (the tic value), it's data BUT
        elif line.split()[0].isnumeric():

            # if headers are empty, we hit numbers before we hit headers
            if not header:
                raise Exception('Unable to parse .log files, no headers found')

            vals = line.split()

            # If there are missing values, such as a trigger pulse,
            # We append values to the end.  Yes, we are assuming they're at the end
            # Given the converter they're using, they seem to try to use tabs to separate columns, but
            # Those apparently end up converted to spaces, so there's no real way of knowing how much whitespace
            # there is between values.  Comma separated would be helpful in the future.
            while len(vals) < len(header):
                vals.append('')

            for h, v in zip(header, vals):
                physio_dict[h].append(v)

        else:
            print('Unrecognized line: {}\nskipping'.format(line))


    if physio_dict['LogDataType'] != 'ACQUISITION_INFO':

        # We can now do some generic modifications for all signals
        physio_dict['CHANNEL'] = np.array(physio_dict['CHANNEL'])
        physio_dict['VALUE'] = np.array(physio_dict['VALUE']).astype(int)
        physio_dict['SIGNAL'] = np.array(physio_dict['SIGNAL'])
        physio_dict['ACQ_TIME_TICS'] = np.array(physio_dict['ACQ_TIME_TICS']).astype(int)

        # First extract the unique channels (4 for ECG) and signals (n for EXT)
        # Typically 1 channel for RESP and PULS but signal can contain triggers from
        # all other channels apparently yay.
        unique_channels = np.unique(physio_dict['CHANNEL'])
        unique_signals = np.unique(physio_dict['SIGNAL'])

        # Store these values in the physio Dict
        physio_dict['Chans'] = set(unique_channels)
        physio_dict['Sigs'] = set(unique_signals)
        physio_dict['Chans'].discard('')
        physio_dict['Sigs'].discard('')

        # Initialize values to be set as we loop through the channels:
        physio_dict['raw_values'] = {}
        physio_dict['raw_tics'] = {}

        for channel in physio_dict['Chans']:
            # Locate the indexes where this channel is associated
            inds = np.where(physio_dict['CHANNEL'] == channel)

            # pull out and store the values and acquisition times of that channel
            physio_dict['raw_values'][channel] = physio_dict['VALUE'][inds]
            physio_dict['raw_tics'][channel] = physio_dict['ACQ_TIME_TICS'][inds]

        for sig in physio_dict['Sigs']:
            # Locate the indexes where this signal shows up
            inds = np.where(physio_dict['SIGNAL'] == sig)

            # Pull out and store the values at those tics.  for raw, it's only tics and values where it's non-zero
            physio_dict['raw_values'][sig] = physio_dict['SIGNAL'][inds]
            physio_dict['raw_tics'][sig] = physio_dict['ACQ_TIME_TICS'][inds]

    return physio_dict


def process_multichan(physio_dict, fill='linear', tic_option='fill'):
    """
    this does the full processing pipeline on each channel and signal.
    (remove_duplicate_tics(), create_new_tic_array(),
         interp_values_to_newtics(), triggers_2_timeseries())

    :param physio_dict:
    :param fill:
    :param tic_option:
    :return:
    """

    rate = int(physio_dict['SampleTime'])
    proc_data = {}
    proc_tics = {}
    min_tic = np.amin(physio_dict['ACQ_TIME_TICS'])
    max_tic = np.amax(physio_dict['ACQ_TIME_TICS'])

    for chan in physio_dict['Chans']:

        tics = physio_dict['raw_tics'][chan]
        values = physio_dict['raw_values'][chan]

        tics, values = remove_duplicate_tics(tics, values)

        new_tics = create_new_tics(tics,rate,min_tic,max_tic, option=tic_option)
        proc_data[chan] = interp_vals(tics, values, new_tics, fill=fill)
        proc_tics[chan] = new_tics

    return proc_tics, proc_data


def sig_2_timeseries(ts_tics, sig_tics):
    """
    This function takes a signal channel (which is an array of index times, indicating at which points a certain trigger
    signal was received), and turns it into a binary timeseries.

    This function works best with time series tics (ts_tics) that have been conditioned in some way to account for
    missing data (such as with create_new_tics)

    :param ts_tics: the tics of the timeseries you wish to map the signal triggers to
    :param sig_tics: the tic times at which signal triggers were recieved.
    :return: the signal timeseries as a function of ts_tics
    """

    sig_ts = np.zeros(len(ts_tics))
    for st in sig_tics:
        ind = np.argmax(ts_tics >= st)
        sig_ts[ind] = 1

    return sig_ts


def remove_duplicate_tics(tics, values):
    """
    takes in a set of values and the tic times of acquisition.  Then removes any duplicate tic samples.  It happens rarely,
    but it must be addressed.

    :param tics: the tic times of the acquired values
    :param values: the values acquired at the tic times
    :return: the cleaned tic and values array.
    """

    # Occasionally there is a duplicate sample for the same timepoint.  Take the one that
    # Is lowest in the array

    duplicates = [item for item, count in Counter(tics).items() if count > 1]
    rminds = []
    for dup in duplicates:
        dup_inds = np.where(tics == dup)[0]
        rminds.append(dup_inds[0])

    values = np.delete(values, rminds)
    tics = np.delete(tics, rminds)

    return tics, values


def eval_sampling_quality(tics, values, rate):
    """
    This produces a QA measure on the sampling rate stability.

    This includes:
    Percent of samples at correct rate
    Amount of time skipped (in Tics and Percent)
    Raw count of number of samples at differnet rates
    expected time (based on length of acquisition) vs actual time (based on true tic times)
    Histogram of the actual data (To identify too many lows or highs)

    :param tics: the tics that the values were sampled at
    :param values: the values sampled at the tics
    :param rate: the desired sampling rate (in tics)
    :return: QA measure dictionary
    """
    values = np.nan_to_num(values)
    qa_dict = {}
    tics = tics - tics[0]

    dt = np.diff(tics)
    rates = Counter(dt)
    n_correct = rates[rate]
    percent_correct = n_correct / len(tics) * 100
    percent_skipped = 100 - percent_correct


    expected_time = len(tics) # ntics/tics per second = seconds
    actual_time = (tics[-1])/rate # actual tics/tics per second = seconds

    offset = actual_time - expected_time

    qa_dict['Skipped_Tics'] = offset
    qa_dict['Percent_Skipped'] = percent_skipped
    qa_dict['Percent_correct'] = percent_correct
    qa_dict['Rate_Count'] = rates
    qa_dict['Expected_Time'] = expected_time
    qa_dict['Actual_Time'] = actual_time

    value_hist = np.histogram(values)

    qa_dict['Values_Hist'] = value_hist

    return qa_dict


def resample_data(tics, values, new_tics, fill='interp'):
    """
    Occasionally in physio data sampling, samples are missed or skipped, especially in high-sampling rate applications.
    Additionally, there is occasionally equipment dropout, leaving chunks of data unsampled.  Further, sometimes ECG
    data channels sample different amounts of data for different lengths of time.  You can resample the physio data to
    one template timeseries if you'd like, though it's not recommeded for anything but ECG really.

    :param tics:
    :param values:
    :param new_tics:
    :param fill:
    :return:
    """

    if isinstance(fill, int) or isinstance(fill, float):
        new_values = np.zeros(len(new_tics)) + fill

        old_tic_n = 0
        old_tic = tics[old_tic_n]
        for it, new_tick in enumerate(new_tics):
            if old_tic == new_tick:
                new_values[it] = values[old_tic_n]
                old_tic_n += 1

    elif fill == 'interp':

        new_values = np.interp(new_tics, tics, values,
                               left=values[0], right=values[-1])

    else:
        raise Exception('Invalid fill value')

    return new_values


def dicts2bids(chan_values, sig_values, new_vol_array):

    """
    This function takes the processed channel values and signal values from a physio object, and prepares a BIDS file.

    :param chan_values:
    :param sig_values:
    :param new_vol_array:
    :return:
    """

    # Initialize BIDS file as matrix of zeros
    chan = list(chan_values.keys())[0]
    ncol = len(chan_values) + len(sig_values) + 1
    nrow = len(chan_values[chan])
    bids_file = np.zeros((nrow, ncol))
    json_headers = []

    # Loop through the channel headers
    nc = 0
    for chan in chan_values.keys():
        bids_file[:,nc] = chan_values[chan]
        json_headers.append(chan)
        nc += 1

    # Now loop through the signal triggers.  Currently set up to be the same for each channel.
    for sig in sig_values.keys():
        bids_file[:,nc] = sig_values[sig]
        json_headers.append(sig)
        nc += 1

    # Now add the new vol tics
    bids_file[:,nc] = new_vol_array
    json_headers.append('scanner')

    return bids_file, json_headers
